---
layout: home
title: FME 2023
subtitle: Foundation Model Ecosystems: Leveraging Data to Simulate, Understand, and Control Multiagent AI Interactions
---

<div class="subsubheading"></div>

<hr class="small" style="border-width: 1pt; border-color: lightgray;">
<!-- <div class="contact-heading">Contact: <a href='mailto:apjacob@mit.edu'>apjacob@mit.edu</a>.</div> -->

<hr class="small" style="border-width: 1pt; border-color: lightgray;">

<!-- <div class='Abstract' style='font-size: 11pt;'>
<h3 style='margin-bottom: 10pt;'>Abstract</h3>
<p>
	Artificial Intelligence (AI) still faces challenges in collaborating with humans as part of a multi-agent system. To develop AI that can seamlessly interact with humans, it is important to promote interdisciplinary collaboration between diverse communities, including multi-agent, game theory, human-AI interaction, and language. This workshop aims to provide a platform for such collaboration and develop human-centric AI.
</p>
</div> -->

<div class='description' style='font-size: 11pt;'>

<h3 style='margin-bottom: 10pt;'>Description</h3>

<p>AI has rapidly become a ubiquitous part of our daily lives, transforming the way we live, work, and interact with technology. From ChatGPT's capacity to suggest code snippets to programmers, to self-driving carsâ€™ ability to navigate challenging traffic scenarios, AI shows great promise for augmenting human capabilities and improving efficiency. Many of these applications of artificial intelligence involve multiple interacting agents, each making decisions according to their own incentives.</p>

<p>However, we are still far from achieving the full potential of AI in collaborating with humans as part of a multi-agent system. Despite significant advancements, many AI systems still struggle to communicate and explain their decision-making processes in a manner that is easily understood by humans. Additionally, AI often fails to accurately model human intentions, leading to suboptimal or even undesirable outcomes.</p>

<p>To address these challenges and realize the full potential of AI in human-centric settings, it is crucial to bring together researchers and practitioners from diverse fields, including multi-agent systems, game theory, human-AI interaction, and language. This workshop aims to provide a platform for interdisciplinary exchange and collaborate to drive the development of human-centric AI for multi-agent systems.</p>

<p>During the workshop, we will delve into several important questions, including:</p>
<p><b>Subtopic: Multi-agent learning</b></p>
<ul>
	<li>How can we accurately model the hidden intention of other agents?</li>
	<li>How can we learn an effective policy when other agents are acting according to non-stationary policies?</li>
	<li>How can we achieve algorithms that scale efficiently w.r.t. the number of agents?</li>
	<li>RL-based techniques are widely used in imperfect information continuous games, online-learning-based techniques in imperfect information tabular games. What is the appropriate synthesis of the two?</li>
	<li> How do we test or validate MARL agents beyond the zero-sum setting?</li>
</ul>

<p><b>Subtopic: Game-theory</b></p>
<ul>
	<li>Many games have multiple equilibria; how can we characterize which equilibria are natural outcomes of agent play, and which lead to socially desirable outcomes?</li>
	<li>Some games have no desirable equilibria (i.e., high price of anarchy). How can we modify the game rules, payoffs, etc to create new equilibria with more desired outcomes?</li>
	<li>It has been proposed that in many settings agents cannot be expected to converge to equilibrium in the first place; what are alternative notions that can be used to model agent behavior?</li>
</ul>

<p><b>Subtopic: Human/AI</b></p>
<ul>
	<li>Recent advances in RLHF have shown how effective learning from human preference data can be. What are some other ways we can learn from human data, especially when it is suboptimal?</li>
	<li>How can we learn from humans interactively (e.g., corrections)?</li>
	<li>How can we coordinate with different human partners in a zero or few-shot manner?</li>
	<li>How can AI agents teach or guide humans? </li>
</ul>

<p><b>Subtopic: Language</b></p>
<ul>
	<li>How can we develop better tools for studying human communication and pragmatics through the lens of multi-agent systems? </li>
	<li>How can we build better language systems that can better collaborate with humans using natural language?</li>
	<li>Can we develop better techniques for aligning language models that interact with humans using tools from the human/AI and multi-agent communities?</li>
</ul>

By gaining novel perspectives from these communities, we hope to build human-centric AI solutions for real-world problems.



</div>
